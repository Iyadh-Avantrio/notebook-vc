{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d308d1a1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import csv\n",
    "from ..celery import app\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "from io import StringIO\n",
    "import logging\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from service.common.other import create_property_name_clean, get_latest_csv_group,get_specific_csv_group\n",
    "from service.common.s3_utils import (log_error_to_csv)\n",
    "from service.common.pipeline_utils import (insert_pipeline_run, update_pipeline_run_by_pipeline_run_id,insert_pipeline_error_log)\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_batch\n",
    "from sqlalchemy import create_engine\n",
    "import json\n",
    "\n",
    "scraped_date = os.getenv('SCRAPED_DATE')\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "ACCESS_ID = os.getenv('ACCESS_ID')\n",
    "ACCESS_KEY = os.getenv('ACCESS_KEY')\n",
    "LISTINGS_INPUT_BUCKET_NAME = os.getenv('LISTINGS_INPUT_BUCKET_NAME')\n",
    "LISTINGS_OUTPUT_BUCKET_NAME = os.getenv('LISTINGS_OUTPUT_BUCKET_NAME')\n",
    "REGION_NAME = os.getenv('REGION_NAME')\n",
    "INPUT_BUCKET_PREFIX = os.getenv('INPUT_BUCKET_PREFIX')\n",
    "DLD_OUTPUT_BUCKET = os.getenv('DLD_OUTPUT_BUCKET')\n",
    "\n",
    "INDEX_FIELD = 'listing_url'\n",
    "\n",
    "DB_HOST = os.getenv('DB_HOST')\n",
    "DB_PORT = os.getenv('DB_PORT')\n",
    "DB_NAME = os.getenv('DB_NAME')\n",
    "DB_USERNAME = os.getenv('DB_USERNAME')\n",
    "DB_PASSWORD = os.getenv('DB_PASSWORD')\n",
    "DB_URI = os.getenv('DB_URI')\n",
    "\n",
    "\n",
    "s3 = boto3.resource('s3', aws_access_key_id=ACCESS_ID,aws_secret_access_key=ACCESS_KEY, region_name=REGION_NAME)\n",
    "s3_client = boto3.client('s3', aws_access_key_id=ACCESS_ID,aws_secret_access_key=ACCESS_KEY, region_name=REGION_NAME)\n",
    "\n",
    "# bucket = s3.Bucket(LISTINGS_INPUT_BUCKET_NAME)\n",
    "# prefix_objs = bucket.objects.filter(Prefix=INPUT_BUCKET_PREFIX + \"/\")\n",
    "bucket = s3.Bucket(\"prop-ai-source-files\")\n",
    "\n",
    "propai_result_frames = []\n",
    "other_result_frames = []\n",
    "\n",
    "marketplace_list = [\"PropertyFinder\", \"Bayut\", \"Dubizzle\"]\n",
    "\n",
    "# common \n",
    "PROPERTY_TYPE_MAP = {\n",
    "    'Studio': 'Apartment',\n",
    "    'Flat': 'Apartment',\n",
    "    'Penthouse': 'Apartment',\n",
    "    'Hotel apartments': 'Hotel Apartment',\n",
    "    'Complex Villas': 'Villa',\n",
    "    'Villa': 'Villa',\n",
    "    'Duplex': 'Apartment',\n",
    "    'Bungalow': \"\",\n",
    "    'Townhouse': \"Villa\"\n",
    "}\n",
    "\n",
    "STATUS_MAP = {\n",
    "    \"off_plan\": \"Off-Plan\",\n",
    "    \"Off_Plan\": \"Off-Plan\",\n",
    "    \"off_plan_primary\": \"Off-Plan\",\n",
    "    \"Off_Plan_Primary\": \"Off-Plan\",\n",
    "    \"under-construction\": \"Off-Plan\",\n",
    "    \"completed_primary\": \"Existing\",\n",
    "    \"completed\": \"Existing\",\n",
    "    \"Completed\": \"Existing\",\n",
    "    \"Completed_primary\":\"Existing\",\n",
    "    \"\":\"Existing\",\n",
    "    'Off_plan':'Off-Plan',\n",
    "    'Ready':\"Existing\"\n",
    "}\n",
    "\n",
    "\n",
    "# bayut\n",
    "supported_types_bayut = [\n",
    "    'apartments',\n",
    "    'apartment',\n",
    "    'penthouses',\n",
    "    'penthouse',\n",
    "    'hotel apartments',\n",
    "    'hotel apartment',\n",
    "    'townhouses',\n",
    "    'townhouse',\n",
    "    'villas',\n",
    "    'villa',\n",
    "    'buildings',\n",
    "    'building',\n",
    "    'plots',\n",
    "    'plot',\n",
    "]\n",
    "\n",
    "bayut_dic = {\n",
    "    'apartments': 'Apartment',\n",
    "    'apartment': 'Apartment',\n",
    "    'penthouses': 'Penthouse',\n",
    "    'penthouse': 'Penthouse',\n",
    "    'hotel apartments': 'Hotel Apartment',\n",
    "    'hotel apartment': 'Hotel Apartment',\n",
    "    'townhouses': 'Townhouse',\n",
    "    'townhouse': 'Townhouse',\n",
    "    'villas': 'Villa',\n",
    "    'villa': 'Villa',\n",
    "    'buildings': 'Building',\n",
    "    'building': 'Building',\n",
    "    'plots': 'Land',\n",
    "    'plot': 'Land',\n",
    "}\n",
    "\n",
    "column_map_bayut = {\n",
    "    'url': 'listing_url',\n",
    "    'website': 'listing_source',\n",
    "    'country': 'country_name',\n",
    "    'city': 'city_name',\n",
    "    'listing_name': 'property_name',\n",
    "    'price': 'asking_price',\n",
    "    'price_currency': 'asking_price_currency',\n",
    "    'property_type': 'property_category',\n",
    "    'property_sub_type': 'property_type',\n",
    "    'address': 'property_address',\n",
    "    'area': 'city_region',\n",
    "    'latitude': 'map_coordinates_latitude',\n",
    "    'longitude': 'map_coordinates_longitude',\n",
    "    'description': 'description',\n",
    "    'for_sale': 'for_sale',\n",
    "    'for_rent': 'for_rent',\n",
    "    'plot_area': 'total_area',\n",
    "    'plot_area_units': 'total_area_units',\n",
    "    'bathroom_count': 'bathrooms_total',\n",
    "    'room_count': 'rooms_total',\n",
    "    'amenities': 'amenities_text',\n",
    "    'date_listed': 'date_listed',\n",
    "    'bayut_reference_number': 'listing_id',\n",
    "    'completion_status': 'completion_status',\n",
    "    'realtor_name': 'list_agent_full_name',\n",
    "    'realtor_email': 'list_agent_email',\n",
    "    'realtor_cell_phone': 'list_agent_mobile_phone',\n",
    "    'realtor_phone': 'list_agent_direct_phone',\n",
    "    'realtor_permit_number': 'list_agent_mls_id',\n",
    "    'agent_name': 'list_agent_full_name',\n",
    "    'agent_email': 'list_agent_email',\n",
    "    'agent_cell_phone': 'list_agent_mobile_phone',\n",
    "    'agent_phone': 'list_agent_direct_phone',\n",
    "    'agency_name': 'list_office_name',\n",
    "    'furnishing_status': 'furnished_info',\n",
    "    'agent_whatsapp': 'agent_whatsapp',\n",
    "    # 'agency_orn':'agency_orn',\n",
    "    'agent_orn':'agent_orn',\n",
    "    'trakheesi_permit_number': 'trakheesi_permit_number',\n",
    "    'rera_trakheesi_listing_permit':'list_agent_mls_id',\n",
    "    'building_name': 'building_name',\n",
    "    'trucheck_verified': 'is_verified',\n",
    "    'dubailand_listing_validation_url':'dubailand_listing_validation_url',\n",
    "    'building_built_date':'building_built_date',\n",
    "    'building_floor_count':'building_floor_count',\n",
    "    'building_builtup_area_sqm':'building_builtup_area_sqm',\n",
    "    'developer_project_name':'developer_project_name',\n",
    "    'listing_floor_number':'listing_floor_number',\n",
    "    'trakheesi_start':'trakheesi_start',\n",
    "    'trakheesi_start':'trakheesi_start',\n",
    "    'trakheesi_end':'trakheesi_end',\n",
    "    'is_qr_code_link_available':'is_qr_code_link_available',\n",
    "    'regulatory_status':'regulatory_status',\n",
    "    'is_permit_delisted':'is_permit_delisted',\n",
    "    'orn_license':'orn_license',\n",
    "    'ded_license':'ded_license',\n",
    "    'rera_license':'rera_license',\n",
    "    'service_charge_sqft':'service_charge_sqft'\n",
    "}\n",
    "\n",
    "\n",
    "# propertyfinder\n",
    "supported_types_propertyfinder = [\n",
    "    'apartment',\n",
    "    'duplex',\n",
    "    'penthouse',\n",
    "    'hotel & hotel apartment',\n",
    "    'townhouse',\n",
    "    'villa',\n",
    "    'bungalow',\n",
    "    'whole building',\n",
    "    'land',\n",
    "]\n",
    "\n",
    "propertyfinder_dic = {\n",
    "    'apartment': 'Apartment',\n",
    "    'duplex': 'Duplex',\n",
    "    'penthouse': 'Penthouse',\n",
    "    'hotel & hotel apartment': 'Hotel Apartment',\n",
    "    'townhouse': 'Townhouse',\n",
    "    'villa': 'Villa',\n",
    "    'bungalow': 'Bungalow',\n",
    "    'whole building': 'Building',\n",
    "    'land': 'Land',\n",
    "}\n",
    "\n",
    "column_map_propertyfinder = {\n",
    "    'url': 'listing_url',\n",
    "    'website': 'listing_source',\n",
    "    'country': 'country_name',\n",
    "    'city': 'city_name',\n",
    "    'listing_name': 'property_name',\n",
    "    'price': 'asking_price',\n",
    "    'price_currency': 'asking_price_currency',\n",
    "    'property_type': 'property_category',\n",
    "    'property_sub_type': 'property_type',\n",
    "    'address': 'property_address',\n",
    "    'area': 'city_region',\n",
    "    'latitude': 'map_coordinates_latitude',\n",
    "    'longitude': 'map_coordinates_longitude',\n",
    "    'description': 'description',\n",
    "    'for_sale': 'for_sale',\n",
    "    'for_rent': 'for_rent',\n",
    "    'built_area': 'total_area',\n",
    "    'built_area_units': 'total_area_units',\n",
    "    'bathroom_count': 'bathrooms_total',\n",
    "    'room_count': 'rooms_total',\n",
    "    'amenities': 'amenities_text',\n",
    "    'date_listed': 'date_listed',\n",
    "    'agent_id': 'list_agent_mls_id',\n",
    "    'agent_call': 'list_agent_mobile_phone',\n",
    "    'agent_name': 'list_agent_full_name',\n",
    "    'email': 'list_agent_email',\n",
    "    'broker_id': 'list_office_mls_id',\n",
    "    'broker_name': 'list_office_name',\n",
    "    'reference': 'listing_id',\n",
    "    'agent_phone': 'list_agent_mobile_phone',\n",
    "    'agent_email': 'list_agent_email',\n",
    "    'agency_id': 'list_office_mls_id',\n",
    "    'propertyfinder_reference_number': 'listing_id',\n",
    "    'completion_status': 'completion_status',\n",
    "    'building_name': 'building_name',\n",
    "    'furnishing_status': 'furnished_info',\n",
    "    'is_furnished': 'furnished_info',\n",
    "    'agent_whatsapp': 'agent_whatsapp',\n",
    "    'is_verified': 'is_verified',\n",
    "    # 'agency_orn_number':'agency_orn',\n",
    "    'agent_orn_number':'agent_orn',\n",
    "    'dubailand_listing_validation_url':'dubailand_listing_validation_url'                           \n",
    "}\n",
    "\n",
    "\n",
    "# dubizzle\n",
    "supported_types_dubizzle = [        \n",
    "    'apartment',\n",
    "    'commercial villa',\n",
    "    'penthouse',\n",
    "    'residential building',\n",
    "    'townhouse',\n",
    "    'villa',\n",
    "    'villa compound'\n",
    "]\n",
    "\n",
    "dubizzle_dic = {\n",
    "    'Apartment':'Apartment',\n",
    "    'Commercial Villa':'Commercial Villa', \n",
    "    'Penthouse':'Penthouse',\n",
    "    'Residential Building':'Resedential Building',\n",
    "    'Townhouse':'Townhouse',\n",
    "    'Villa':'Villa',\n",
    "    'Villa Compound':'Villa Compound'\n",
    "}\n",
    "\n",
    "column_map_dubizzle = {\n",
    "    'url': 'listing_url',\n",
    "    'country': 'country_name',\n",
    "    'city': 'city_name',\n",
    "    'region': 'city_region',\n",
    "    'location':'property_address',\n",
    "    'address':'property_address',\n",
    "    'property_category': 'property_category',\n",
    "    'agency_id':'list_office_mls_id',\n",
    "    'agency_name':'list_office_name',   \n",
    "    'agent_name': 'list_agent_full_name',\n",
    "    'agent_email': 'list_agent_email',\n",
    "    'agent_id': 'list_agent_mls_id',\n",
    "    'agent_phone': 'list_agent_mobile_phone',\n",
    "    'agent_brn':'agent_brn_number',              \n",
    "    'listing_price': 'asking_price',\n",
    "    'listing_price_currency': 'asking_price_currency',\n",
    "    'listing_size': 'total_area',\n",
    "    'listing_bathrooms': 'bathrooms_total',\n",
    "    'listing_bedrooms':'rooms_total',\n",
    "    'amenities': 'amenities_text',                         \n",
    "    'lat': 'map_coordinates_latitude',\n",
    "    'lon': 'map_coordinates_longitude',\n",
    "    'listing_description': 'description',\n",
    "    'listing_name': 'property_name',\n",
    "    'trakheesi_permit_number':'trakheesi_permit_number',               \n",
    "    'property_sub_category': 'property_type',\n",
    "    'property_furnished':'furnished_info',\n",
    "    'property_completion_status': 'completion_status',\n",
    "    'for_sale': 'for_sale',\n",
    "    'for_rent': 'for_rent',\n",
    "    'property_updated_at': 'date_listed',\n",
    "    'property_listing_id': 'listing_id',\n",
    "    'dubailand_listing_validation_url':'dubailand_listing_validation_url',\n",
    "    'photos_main_urls':'photo_urls',                   \n",
    "    'building_name': 'building_name',   \n",
    "    # 'rera_registration_number':'agency_orn',                                \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "@app.task\n",
    "def process(task_chain_name, scraped_date=None, marketplace=None, task_id=None):\n",
    "    \"\"\"_summary_\n",
    "    Triggers the CSV processing function for a specified marketplace or for all marketplaces.\n",
    "    Args:\n",
    "        scraped_date (_type_, optional):\n",
    "            The date of the scraped data. \n",
    "            Defaults to None.\n",
    "        marketplace (_type_, optional): \n",
    "            The marketplace to process (e.g., \"propertyfinder\", \"bayut\", \"dubizzle\").\n",
    "            Defaults to None.\n",
    "    \"\"\"\n",
    "    if not scraped_date:\n",
    "        logging.error(\"scraped_date is required but not provided.\")\n",
    "        return\n",
    "    \n",
    "    task_name = f'Active Listing - {marketplace}'\n",
    "    pipeline_details = {\n",
    "        \"pipeline_name\": task_name,\n",
    "        \"pipeline_name_code\": task_chain_name,\n",
    "        \"pipeline_run_id\": task_id,\n",
    "        \"scraped_date\": scraped_date,        \n",
    "        \"marketplace\": marketplace,\n",
    "    }\n",
    "    task_id = insert_pipeline_run(pipeline_details)\n",
    "    \n",
    "    try:\n",
    "        print(f\"marketplace: {marketplace} , scraped_date: {scraped_date}\")\n",
    "        if(marketplace):\n",
    "            logging.info(f'CSV processing triggered for marketplace: {marketplace}')\n",
    "        else:\n",
    "            logging.info('CSV processing function triggered for all marketplaces')\n",
    "        \n",
    "        \n",
    "        # Define the marketplace keywords you're looking for\n",
    "        if (marketplace):\n",
    "            required_marketplaces = [marketplace.lower()]\n",
    "        else:\n",
    "            required_marketplaces = ['bayut', 'dubizzle', 'propertyfinder']\n",
    "\n",
    "        # A dictionary to track if the files for each marketplace exist\n",
    "        marketplace_files = {required_marketplace: False for required_marketplace in required_marketplaces}\n",
    "\n",
    "        # Loop through the objects in the bucket and check the presence of files for each marketplace\n",
    "        prefix_objs = bucket.objects.filter(Prefix=\"propai\" + \"/\" + scraped_date + \"/\")\n",
    "        all_csvs = []\n",
    "        csvs = []\n",
    "        for obj in prefix_objs:\n",
    "            if obj.key.endswith('.csv'):\n",
    "                all_csvs.append(obj.key)\n",
    "                csvs.append(s3_client.get_object(\n",
    "                    Bucket=\"prop-ai-source-files\", Key=obj.key))\n",
    "\n",
    "                # Check which marketplace the file belongs to\n",
    "                for required_marketplace in required_marketplaces:\n",
    "                    if required_marketplace in obj.key:\n",
    "                        marketplace_files[required_marketplace] = True\n",
    "\n",
    "        # Check if all required marketplaces have files\n",
    "        missing_marketplaces = [required_marketplace for required_marketplace, exists in marketplace_files.items() if not exists]\n",
    "        if missing_marketplaces:\n",
    "            raise ValueError(f\"Missing CSV files for marketplaces: {', '.join(missing_marketplaces)}\")\n",
    "        else:\n",
    "            print(\"All required marketplaces are present. Proceeding with the next steps.\")\n",
    "\n",
    "\n",
    "        logging.info(f'CSV processing started for marketplace: {marketplace}')\n",
    "        process_cvs([all_csvs], marketplace)\n",
    "        logging.info('CSV processing finished successfully')        \n",
    "        update_pipeline_run_by_pipeline_run_id(task_id, {\"run_status\":'SUCCESS'})\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        error_file = log_error_to_csv(task_name, str(e), LISTINGS_OUTPUT_BUCKET_NAME)\n",
    "        insert_pipeline_error_log(task_id,{\"error_message\":str(e)})        \n",
    "        update_pipeline_run_by_pipeline_run_id(task_id,{\"run_status\":'FAILED', \"run_status_info\":str(e), \"error_file\":error_file})\n",
    "\n",
    "\n",
    "def agency_orn_fillna_for_markerplace(df):\n",
    "    \"\"\"\n",
    "    Fills missing values in the 'agency_orn' column using values from 'agency_orn_number', \n",
    "    'orn_license', and 'rera_registration_number' columns (in that order).\n",
    "    \"\"\"\n",
    "    df['agency_orn'] = (df.get('agency_orn', pd.Series([pd.NA] * len(df))) \n",
    "                        .fillna(df.get('agency_orn_number', pd.Series([pd.NA] * len(df)))) \n",
    "                        .fillna(df.get('orn_license', pd.Series([pd.NA] * len(df)))) \n",
    "                        .fillna(df.get('rera_registration_number', pd.Series([pd.NA] * len(df)))))\n",
    "    \n",
    "    if 'rera_registration_number' in df.columns:\n",
    "        df.drop(columns=['rera_registration_number'], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# process_cvs\n",
    "def process_cvs(grouped_objects, marketplace=None, task_id=None):\n",
    "    for csvs in grouped_objects:\n",
    "        csv_folder_name = csvs[0].split('/')[1] \n",
    "        try:\n",
    "            for csv_name in csvs:\n",
    "                bayut_key = 'ae_bayut_listing_' + \\\n",
    "                    csv_name.split('/')[1].replace('-', '') + '.csv'\n",
    "                propertyfinder_key = 'ae_propertyfinder_listing_' + \\\n",
    "                    csv_name.split('/')[1].replace('-', '') + '.csv'\n",
    "                zoom_key = 'ae_zoomproperty_listing_' + \\\n",
    "                    csv_name.split('/')[1].replace('-', '') + '.csv'\n",
    "                dubizzle_key = 'ae_dubizzle_listing_' + \\\n",
    "                    csv_name.split('/')[1].replace('-', '') + '.csv' \n",
    "        except:\n",
    "            raise ValueError(\"incorrect values\")\n",
    "        \n",
    "        logging.info(f'CSVs to be processed for marketplace: {marketplace}')\n",
    "\n",
    "        # Load the correct source columns based on the date and marketplace\n",
    "        if marketplace == \"PropertyFinder\":\n",
    "            source_column_name_list_propertyfinder = get_source_column_name_lists_dicts_by_date(csv_folder_name)[\"propertyfinder\"]                            \n",
    "        elif marketplace == \"Bayut\":    \n",
    "            source_column_name_list_bayut = get_source_column_name_lists_dicts_by_date(csv_folder_name)[\"bayut\"]        \n",
    "        elif marketplace == \"Dubizzle\":\n",
    "            source_column_name_list_dubizzle = get_source_column_name_lists_dicts_by_date(csv_folder_name)[\"dubizzle\"]\n",
    "        else: \n",
    "           source_column_name_list_dubizzle = get_source_column_name_lists_dicts_by_date(csv_folder_name)[\"dubizzle\"]\n",
    "           source_column_name_list_propertyfinder = get_source_column_name_lists_dicts_by_date(csv_folder_name)[\"propertyfinder\"]                            \n",
    "           source_column_name_list_bayut = get_source_column_name_lists_dicts_by_date(csv_folder_name)[\"bayut\"]       \n",
    "        \n",
    "\n",
    "        # Process only the marketplace specified\n",
    "        if marketplace == \"Bayut\":\n",
    "            process_bayut(csv_folder_name, bayut_key, source_column_name_list_bayut)\n",
    "        elif marketplace == \"PropertyFinder\":\n",
    "            process_propertyfinder(csv_folder_name, propertyfinder_key, source_column_name_list_propertyfinder)\n",
    "        elif marketplace == \"Dubizzle\":\n",
    "            process_dubizzle(csv_folder_name, dubizzle_key, source_column_name_list_dubizzle)\n",
    "        else:\n",
    "            process_dubizzle(csv_folder_name, dubizzle_key, source_column_name_list_dubizzle)\n",
    "            process_bayut(csv_folder_name, bayut_key, source_column_name_list_bayut)\n",
    "            process_propertyfinder(csv_folder_name, propertyfinder_key, source_column_name_list_propertyfinder)\n",
    "            \n",
    "        process_result_frames(csv_folder_name, marketplace)\n",
    "\n",
    "def process_bayut(csv_folder_name, bayut_key, source_column_name_list_bayut):\n",
    "    try:\n",
    "        df = pd.read_csv(f's3://prop-ai-source-files/propai/{csv_folder_name}/{bayut_key}', header=0, storage_options={\"key\": ACCESS_ID, \"secret\": ACCESS_KEY})\n",
    "        if 'listing_floor_count' in df.columns:\n",
    "            df.rename(columns={'listing_floor_count': 'listing_floor_number'}, inplace=True)\n",
    "        print(df.info())\n",
    "        df2 = df[source_column_name_list_bayut]\n",
    "\n",
    "        num_of_records = df2.shape[0]\n",
    "        print(\"Number of records Bayut:\", num_of_records)\n",
    "        bayut_present=True\n",
    "\n",
    "        df2 = agency_orn_fillna_for_markerplace(df2)\n",
    "\n",
    "        df2 = df2.rename(columns = column_map_bayut)\n",
    "        df2['listing_source'] = \"Bayut\"\n",
    "        df2['country_name'] = \"UAE\"\n",
    "\n",
    "        num_of_records = df2.shape[0]\n",
    "        print(\"Number of records Bayut:\", num_of_records)\n",
    "        df2['property_category'] = df2['property_category'].str.lower()\n",
    "        df2 = df2[df2['property_category'] == \"residential\"]\n",
    "        num_of_records = df2.shape[0]\n",
    "        print(\"Number of records Bayut:\", num_of_records)\n",
    "            \n",
    "        df2['property_type'] = df2['property_type'].str.lower()\n",
    "        df2 = df2[df2['property_type'].isin(supported_types_bayut)]\n",
    "\n",
    "        num_of_records = df2.shape[0]\n",
    "        print(\"Number of records Bayut:\", num_of_records)\n",
    "        print(df2['for_sale'].unique())\n",
    "        print(df2['for_rent'].unique())\n",
    "\n",
    "        print(df2['for_sale'].unique())\n",
    "        print(df2['for_rent'].unique())\n",
    "\n",
    "        print(df2[['for_sale', 'for_rent']].dtypes)\n",
    "\n",
    "        df2 = df2[(df2['for_sale'] == True) | (df2['for_rent'] == True)]\n",
    "        num_of_records = df2.shape[0]\n",
    "        print(\"Number of records Bayut:\", num_of_records)\n",
    "\n",
    "        df2['property_category'] = df2['property_category'].str[:1].str.upper() + df2['property_category'].str[1:]\n",
    "        df2['total_area_sqm'] = df2['total_area']\n",
    "        df2['total_area_sqft'] = df2['total_area']\n",
    "\n",
    "        df2.loc[df2['country_name'] == 'United Arab Emirates', 'country_name'] = 'UAE'\n",
    "\n",
    "        num_of_records = df2.shape[0]\n",
    "        print(\"Number of records Bayut:\", num_of_records)\n",
    "\n",
    "        # Assuming df2 is your DataFrame\n",
    "        print(df2['total_area'].dtype)  # Check data type of 'total_area'\n",
    "\n",
    "        # Convert 'total_area' to numeric, handling errors\n",
    "        df2['total_area'] = pd.to_numeric(df2['total_area'], errors='coerce')\n",
    "\n",
    "        df2.loc[df2['total_area_units'].str.lower() == 'sqm', 'total_area_sqft'] = df2['total_area'] * 10.7639\n",
    "        df2.loc[df2['total_area_units'].str.lower() == 'sqft', 'total_area_sqm'] = df2['total_area'] * 0.092903\n",
    "\n",
    "        df2['property_type'].replace(bayut_dic, inplace=True)\n",
    "\n",
    "        df2['date_listed'] = pd.to_datetime(df2[\"date_listed\"], dayfirst=True, format='mixed').dt.strftime('%d/%m/%Y')\n",
    "        df2[\"date_scraped\"] = csv_folder_name\n",
    "        df2['date_scraped'] = pd.to_datetime(df2['date_scraped'], format='%Y-%m-%d', errors='coerce')\n",
    "        df2 = df2.drop(['total_area', 'total_area_units'], axis=1)\n",
    "\n",
    "        df2 = df2.assign(furnished_yn=(df2[\"furnished_info\"] ==\"furnished\"))\n",
    "\n",
    "        num_of_records = df2.shape[0]\n",
    "        print(\"Number of records Bayut:\", num_of_records)\n",
    "            \n",
    "        try:\n",
    "            #merging photo urls\n",
    "            bayut_photo_key = bayut_key.replace('listing', 'photo')\n",
    "            df_photo = pd.read_csv(f's3://prop-ai-source-files/propai/{csv_folder_name}/{bayut_photo_key}', header=0, storage_options={\"key\": ACCESS_ID, \"secret\": ACCESS_KEY})\n",
    "            photos = df_photo.groupby('url')['photo_url'].agg(list).reset_index().rename(columns={'photo_url':'photo_urls'})\n",
    "            num_of_records = df2.shape[0]\n",
    "            print(\"Number of records Bayut:\", num_of_records)\n",
    "            df2 = pd.merge(df2, photos,left_on=\"listing_url\", right_on=\"url\").drop(\"url\", axis=1)\n",
    "        except Exception as e:\n",
    "            logging.exception('Error while merging photo URLs: %s', str(e))\n",
    "\n",
    "        #other fields on df\n",
    "        propai_columns_bayut = [x for x in source_column_name_list_bayut if x not in ['url']]\n",
    "        df = df.drop(propai_columns_bayut, axis=1)\n",
    "        df = df.rename(columns = {'url':INDEX_FIELD})\n",
    "        \n",
    "        # Append to global lists\n",
    "        other_result_frames.append(df)\n",
    "        propai_result_frames.append(df2)   \n",
    "    except Exception as e:\n",
    "        logging.exception('Error processing Bayut: %s', str(e))\n",
    "\n",
    "def process_propertyfinder(csv_folder_name, propertyfinder_key, source_column_name_list_propertyfinder):\n",
    "    try:\n",
    "        df3 = pd.read_csv(f's3://prop-ai-source-files/propai/{csv_folder_name}/{propertyfinder_key}', header=0, storage_options={\"key\": ACCESS_ID, \"secret\": ACCESS_KEY})\n",
    "        print(df3.info())\n",
    "        \n",
    "        if 'dubailand_listing_validation_url' not in df3.columns:\n",
    "            df3['dubailand_listing_validation_url'] = ''\n",
    "        \n",
    "        df4 = df3[source_column_name_list_propertyfinder]\n",
    "        num_of_records = df4.shape[0]\n",
    "        print(\"Number of records Propertyfinder:\", num_of_records)\n",
    "\n",
    "        df4 = agency_orn_fillna_for_markerplace(df4)\n",
    "\n",
    "        df4 = df4.rename(columns = column_map_propertyfinder)\n",
    "        property_finder_present=True\n",
    "        df4 = df4.drop(columns=['agency_orn_number'])\n",
    "        df4['listing_source'] = \"PropertyFinder\"  \n",
    "    \n",
    "        num_of_records = df4.shape[0]\n",
    "        print(\"Number of records Propertyfinder:\", num_of_records)\n",
    "        df4 = df4[df4['property_category'] == \"residential\"]\n",
    "        num_of_records = df4.shape[0]\n",
    "        print(\"Number of records Propertyfinder:\", num_of_records)\n",
    "\n",
    "        df4['property_type'] = df4['property_type'].str.lower()\n",
    "        df4 = df4[df4['property_type'].isin(supported_types_propertyfinder)] \n",
    "        num_of_records = df4.shape[0]\n",
    "        print(\"Number of records Propertyfinder:\", num_of_records)\n",
    "        df4 = df4[(df4['for_sale'] == True) | (df4['for_rent'] == True)]\n",
    "\n",
    "        num_of_records = df4.shape[0]\n",
    "        print(\"Number of records Propertyfinder:\", num_of_records)\n",
    "\n",
    "        df4['property_category'] = df4['property_category'].str[:1].str.upper() + df4['property_category'].str[1:]\n",
    "        df4['total_area_sqm'] = df4['total_area']\n",
    "        df4['total_area_sqft'] = df4['total_area']\n",
    "\n",
    "        df4.loc[df4['country_name'] == 'United Arab Emirates', 'country_name'] = 'UAE'\n",
    "\n",
    "        df4.loc[df4['total_area_units'].str.lower() == 'sqm', 'total_area_sqft'] = df4['total_area'] * 10.7639\n",
    "        df4.loc[df4['total_area_units'].str.lower() == 'sqft', 'total_area_sqm'] = df4['total_area'] * 0.092903\n",
    "\n",
    "        num_of_records = df4.shape[0]\n",
    "        print(\"Number of records Propertyfinder:\", num_of_records)\n",
    "\n",
    "        df4['property_type'].replace(propertyfinder_dic, inplace=True)\n",
    "\n",
    "        df4['date_listed'] = pd.to_datetime(df4[\"date_listed\"], dayfirst=True, format='mixed').dt.strftime('%d/%m/%Y')\n",
    "        df4[\"date_scraped\"] = csv_folder_name\n",
    "        df4['date_scraped'] = pd.to_datetime(df4['date_scraped'], format='%Y-%m-%d', errors='coerce')\n",
    "        df4 = df4.drop(['total_area', 'total_area_units'], axis=1)\n",
    "        df4['furnished_info'] = df4['furnished_info'].map({True: 'furnished', False: 'unfurnished'})\n",
    "\n",
    "        num_of_records = df4.shape[0]\n",
    "        print(\"Number of records Propertyfinder:\", num_of_records)\n",
    "\n",
    "        df4 = df4.assign(furnished_yn=df4[\"furnished_info\"])\n",
    "        try:\n",
    "            #merging photo urls\n",
    "            propertyfinder_photo_key = propertyfinder_key.replace('listing', 'photo')\n",
    "            # df_photo = pd.read_csv(f's3://{INPUT_BUCKET_NAME}/propai/{csv_folder_name}/{propertyfinder_photo_key}', header=0)\n",
    "            df_photo = pd.read_csv(f's3://prop-ai-source-files/propai/{csv_folder_name}/{propertyfinder_photo_key}', header=0, storage_options={\"key\": ACCESS_ID, \"secret\": ACCESS_KEY})\n",
    "                \n",
    "            photos = df_photo.groupby('url')['photo_url'].agg(list).reset_index().rename(columns={'photo_url':'photo_urls'})\n",
    "            df4 = pd.merge(df4, photos,left_on=\"listing_url\", right_on=\"url\").drop(\"url\", axis=1)\n",
    "\n",
    "            num_of_records = df4.shape[0]\n",
    "            print(\"Number of records Propertyfinder:\", num_of_records)\n",
    "        except Exception as e:\n",
    "            logging.exception('Error while merging photo URLs: %s', str(e))\n",
    "            property_finder_present=False\n",
    "            #other fields on df\n",
    "            propai_columns_propertyfinder = [x for x in source_column_name_list_propertyfinder if x not in ['url']]\n",
    "            df3 = df3.drop(propai_columns_propertyfinder, axis=1)\n",
    "            df3 = df3.rename(columns = {'url':INDEX_FIELD})\n",
    "            \n",
    "        # Append to global lists\n",
    "        other_result_frames.append(df3)\n",
    "        propai_result_frames.append(df4) \n",
    "    except Exception as e:\n",
    "        logging.exception('Error processing PropertyFinder: %s', str(e))\n",
    "\n",
    "def process_dubizzle(csv_folder_name, dubizzle_key, source_column_name_list_dubizzle):\n",
    "    try:\n",
    "        print(f's3://prop-ai-source-files/propai/{csv_folder_name}/{dubizzle_key}')\n",
    "        df7 = pd.read_csv(f's3://prop-ai-source-files/propai/{csv_folder_name}/{dubizzle_key}', header=0, storage_options={\"key\": ACCESS_ID, \"secret\": ACCESS_KEY})\n",
    "        print(len(df7))\n",
    "\n",
    "        if 'location' in df7.columns:\n",
    "            df7.rename(columns={'location': 'address'}, inplace=True) \n",
    "        # Check if the column 'photos_main_urls' exists; if not, add it\n",
    "        if 'photos_main_urls' not in df7.columns:\n",
    "            df7['photos_main_urls'] = '' \n",
    "        print(\"Dubizzle\")\n",
    "        print(df7.info())\n",
    "            \n",
    "        rename_dict = {\n",
    "                'area': 'region',\n",
    "                'property_type': 'property_category',\n",
    "                'agent_bayut_id': 'agent_id',\n",
    "                'agent_brn_number': 'agent_brn',\n",
    "                'price': 'listing_price',\n",
    "                'price_currency': 'listing_price_currency',\n",
    "                'built_area': 'listing_size',\n",
    "                'bathroom_count': 'listing_bathrooms',\n",
    "                'room_count': 'listing_bedrooms',\n",
    "                'latitude': 'lat',\n",
    "                'longitude': 'lon',\n",
    "                'rera_permit_number': 'trakheesi_permit_number',\n",
    "                'property_sub_type': 'property_sub_category',\n",
    "                'furnishing_status': 'property_furnished',\n",
    "                'completion_status': 'property_completion_status',\n",
    "                'updated_at': 'property_updated_at',\n",
    "                'website_provided_id': 'property_listing_id',\n",
    "                'tower_name': 'building_name',\n",
    "                'description':'listing_description'\n",
    "        }\n",
    "            \n",
    "        # df7.rename(columns=rename_dict, inplace=True)\n",
    "            \n",
    "        df8 = df7[source_column_name_list_dubizzle]\n",
    "        dubizzle_present=True\n",
    "        df8 = agency_orn_fillna_for_markerplace(df8)\n",
    "\n",
    "        df8 = df8.rename(columns = column_map_dubizzle)\n",
    "        df8['listing_source'] = \"Dubizzle\"                \n",
    "        df8 = df8[df8['property_category'] == \"residential\"]\n",
    "        print('df8 - 631') \n",
    "        print(df8.info())\n",
    "        unique_values_counts = df8['property_type'].value_counts()\n",
    "        # Display the unique values and their counts\n",
    "        print(\"Unique values and their counts:\")\n",
    "        print(unique_values_counts)\n",
    "        \n",
    "        # Normalize the 'property_type' column to lowercase\n",
    "        df8['property_type'] = df8['property_type'].str.lower()\n",
    " \n",
    "        df8 = df8[df8['property_type'].isin(supported_types_dubizzle)]\n",
    "        df8 = df8[(df8['for_sale'] == True) | (df8['for_rent'] == True)]\n",
    "        \n",
    "        df8['property_category'] = df8['property_category'].str[:1].str.upper() + df8['property_category'].str[1:]\n",
    "        df8['total_area_sqm'] = df8['total_area']\n",
    "        df8['total_area_sqft'] = df8['total_area']\n",
    "\n",
    "        df8['total_area_units']='sqft'\n",
    "        print('df8 - 645') \n",
    "        print(df8.info())\n",
    "\n",
    "        df8.loc[df8['total_area_units'].str.lower() == 'sqm', 'total_area_sqft'] = df8['total_area'] * 10.7639\n",
    "        df8.loc[df8['total_area_units'].str.lower() == 'sqft', 'total_area_sqm'] = df8['total_area'] * 0.092903\n",
    "        df8['property_type'].replace(dubizzle_dic, inplace=True)\n",
    "\n",
    "        print('df8 - 652') \n",
    "        print(df8.info())\n",
    "        \n",
    "        # Replace \":\" after the date part with a space\n",
    "        df8['date_listed'] = df8['date_listed'].str.replace(r'(\\d{4}-\\d{2}-\\d{2}):', r'\\1 ', regex=True)\n",
    "\n",
    "        \n",
    "        df8['date_listed'] = pd.to_datetime(df8[\"date_listed\"], dayfirst=True, format='mixed').dt.strftime('%d/%m/%Y')\n",
    "        df8[\"date_scraped\"] = csv_folder_name\n",
    "        df8['date_scraped'] = pd.to_datetime(df8['date_scraped'], format='%Y-%m-%d', errors='coerce')\n",
    "        df8 = df8.drop(['total_area', 'total_area_units'], axis=1)\n",
    "\n",
    "        df8['photo_urls'] = df8['photo_urls'].apply(lambda x: x.strip(\"[]\").split(\", \"))\n",
    "        print('df8 - 661') \n",
    "        print(df8.info())\n",
    "        df8 = df8.assign(furnished_yn=(df8[\"furnished_info\"] ==\"Furnished\"))\n",
    "        \n",
    "        print('df7') \n",
    "        print(df7.info()) \n",
    "        print('df8')\n",
    "\n",
    "        print(df8.info())\n",
    "        print(\"Dubizzle finished\")\n",
    "\n",
    "        # Append to global lists\n",
    "        other_result_frames.append(df7)\n",
    "        propai_result_frames.append(df8)    \n",
    "\n",
    "        propai_output_frame = pd.concat(propai_result_frames, ignore_index=True)\n",
    "          \n",
    "        unique_listing_sources = propai_output_frame['listing_source'].unique()\n",
    "        # Printing the unique values\n",
    "        print(\"unique_listing_sources in propai_output_frame:\")\n",
    "        print(unique_listing_sources)    \n",
    "    except Exception as e: \n",
    "        logging.exception('Error processing Dubizzle: %s', str(e))\n",
    "\n",
    "def process_result_frames(csv_folder_name, marketplace):\n",
    "    propai_output_frame = pd.concat(propai_result_frames, ignore_index=True)\n",
    "          \n",
    "    unique_listing_sources = propai_output_frame['listing_source'].unique()\n",
    "    # Printing the unique values\n",
    "    print(\"unique_listing_sources in propai_output_frame:\")\n",
    "    print(unique_listing_sources)\n",
    "        \n",
    "    other_output_frame = pd.concat(other_result_frames, ignore_index=True)\n",
    "    propai_output_frame['photo_urls'] = propai_output_frame[\"photo_urls\"].apply(lambda x: create_photo_url_objs(x))\n",
    "    propai_output_frame[\"property_address_clean\"] = propai_output_frame[\"property_address\"].apply(clean_address)\n",
    "       \n",
    "    all_listings_frame = propai_output_frame.copy()\n",
    "    \n",
    "    # Ensure that 'is_verified' is present in all_listings_frame\n",
    "    if 'is_verified' not in all_listings_frame.columns:\n",
    "        all_listings_frame['is_verified'] = False    \n",
    "\n",
    "    #address population for latest stuff\n",
    "    # dubai_address_mapping_frame = new_cheat_df.copy()\n",
    "    all_listings_frame['property_address_clean'] = all_listings_frame['property_address_clean'].str.replace('UNITED ARAB EMIRATES', '', regex=False)\n",
    "    all_listings_frame['property_address_clean'] = all_listings_frame['property_address_clean'].str.replace('UAE', '', regex=False)\n",
    "    all_listings_frame['property_address_clean'] = all_listings_frame['property_address_clean'].str.replace(r'\\bDUBAI\\s+DUBAI\\b', 'DUBAI', regex=True)\n",
    "\n",
    "    # Remove any leading and trailing whitespaces\n",
    "    all_listings_frame['property_address_clean'] = all_listings_frame['property_address_clean'].str.strip()\n",
    "\n",
    "    # cheat_df_old= create_cheatsheet_from_db(DATABASE, 'dubai_address_mapping')\n",
    "    cheat_df_old =pd.read_csv(f's3://{LISTINGS_OUTPUT_BUCKET_NAME}/extra/old_address_mapping.csv', storage_options={\"key\": ACCESS_ID, \"secret\": ACCESS_KEY}, header=0)\n",
    "    cheat_df_old = cheat_df_old.rename(columns={'Address': 'address'})\n",
    "    cheat_df_old['address'] = cheat_df_old['address'].drop_duplicates()\n",
    "    cheat_df_old['address'] =  cheat_df_old['address'].str.replace('UAE', '', regex=False)\n",
    "    cheat_df_old['address'] = cheat_df_old['address'].str.replace('UNITED ARAB EMIRATES', '', regex=False)\n",
    "    cheat_df_old['address'] = cheat_df_old['address'].str.replace(r'\\bDUBAI\\s+DUBAI\\b', 'DUBAI', regex=True)\n",
    "    cheat_df_old['address'] =  cheat_df_old['address'].str.strip()\n",
    "\n",
    "    all_listings_frame = pd.merge(all_listings_frame, cheat_df_old, how=\"left\", left_on=[\"property_address_clean\"], right_on=[\"address\"])\n",
    "    all_listings_frame = all_listings_frame.drop_duplicates(subset='listing_url')\n",
    "\n",
    "    # cheat_df_new= create_cheatsheet_from_db(DATABASE, 'propai_listings_address_mapping')\n",
    "    cheat_df_new =pd.read_csv(f's3://{LISTINGS_OUTPUT_BUCKET_NAME}/extra/new_address_mapping.csv', storage_options={\"key\": ACCESS_ID, \"secret\": ACCESS_KEY}, header=0)\n",
    "    cheat_df_new['address'] = cheat_df_new['address'].drop_duplicates()\n",
    "    cheat_df_new['address'] =  cheat_df_new['address'].str.replace('UAE', '', regex=False)\n",
    "    cheat_df_new['address'] = cheat_df_new['address'].str.replace('UNITED ARAB EMIRATES', '', regex=False)\n",
    "    cheat_df_new['address'] = cheat_df_new['address'].str.replace(r'\\bDUBAI\\s+DUBAI\\b', 'DUBAI', regex=True)\n",
    "    cheat_df_new['address'] =  cheat_df_new['address'].str.strip()\n",
    "\n",
    "    all_listings_frame = pd.merge(all_listings_frame, cheat_df_new, how=\"left\", left_on=[\"property_address_clean\"], right_on=[\"address\"])\n",
    "    all_listings_frame = all_listings_frame.drop_duplicates(subset='listing_url')\n",
    "    # Drop the 'address_y' column\n",
    "    all_listings_frame = all_listings_frame.drop(columns=['address_y'])\n",
    "    all_listings_frame = all_listings_frame.drop(columns=['_id_x'])\n",
    "    all_listings_frame = all_listings_frame.drop(columns=['_id_y'])\n",
    "\n",
    "    # Rename 'address_x' to 'address'\n",
    "    all_listings_frame = all_listings_frame.rename(columns={'address_x': 'address'})\n",
    "\n",
    "    #---------------------------------------------- agent details -------------------------------------------------------\n",
    "    agent_details= pd.read_csv(f's3://{LISTINGS_OUTPUT_BUCKET_NAME}/extra/dld_agents_public.csv', storage_options={\"key\": ACCESS_ID, \"secret\": ACCESS_KEY}, header=0)\n",
    "    agent_details['agent_brn_number'] = agent_details['agent_brn_number'].drop_duplicates()\n",
    "        \n",
    "    # Convert 'agent_brn_number' column to string in both DataFrames\n",
    "    all_listings_frame['agent_brn_number'] = all_listings_frame['agent_brn_number'].astype(str)\n",
    "    agent_details['agent_brn_number'] = agent_details['agent_brn_number'].astype(str)\n",
    "\n",
    "    # Merge the DataFrames\n",
    "    all_listings_frame = pd.merge(all_listings_frame, agent_details, how=\"left\", left_on=[\"agent_brn_number\"], right_on=[\"agent_brn_number\"])\n",
    "    # Fill NaN values in 'agent_brn_number' column with an empty string\n",
    "    all_listings_frame['agent_brn_number'] = all_listings_frame['agent_brn_number'].fillna(\"\")\n",
    "    # Replace \"nan\" strings with an empty string \"\" in the 'agent_brn_number' column\n",
    "    all_listings_frame['agent_brn_number'] = all_listings_frame['agent_brn_number'].replace(\"nan\", \"\")\n",
    "    #---------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    all_listings_frame = all_listings_frame.rename(columns={\n",
    "        'project_name_prop-ai':'project_name_prop_ai' ,\n",
    "        'master_project_prop-ai':'master_project_prop_ai' ,\n",
    "        'area_name_prop-ai':'area_name_prop_ai' ,\n",
    "        'development_name_prop-ai':'development_name_prop_ai' \n",
    "        # Add more columns as needed\n",
    "    })\n",
    "        \n",
    "    # all_listings_frame = pd.merge(all_listings_frame, cheat_df, how=\"left\", left_on=[\"property_address_clean\"], right_on=[\"address\"])\n",
    "\n",
    "    object_cols = all_listings_frame.select_dtypes(include=['object']).columns.tolist()\n",
    "    all_listings_frame[object_cols] = all_listings_frame[object_cols].fillna('')\n",
    "\n",
    "    # all_listings_frame[\"Development Name\"] = all_listings_frame[\"development_name\"]\n",
    "    # all_listings_frame[\"development_name\"] = all_listings_frame.apply(merge_columns, axis=1)\n",
    "    all_listings_frame['is_verified'] = all_listings_frame['is_verified'].apply(map_values)\n",
    "    all_listings_frame[\"Property Type\"] = all_listings_frame[\"property_type\"].replace(PROPERTY_TYPE_MAP)\n",
    "    all_listings_frame[\"Number of Bedrooms\"] = all_listings_frame[\"rooms_total\"]\n",
    "    all_listings_frame[\"Development Status\"] = all_listings_frame[\"completion_status\"].replace(STATUS_MAP)\n",
    "    all_listings_frame[\"Area in SQM\"] = all_listings_frame[\"total_area_sqft\"] / 10.7639\n",
    "    all_listings_frame['asking_price'] = pd.to_numeric(all_listings_frame['asking_price'], errors='coerce')\n",
    "    all_listings_frame['Area in SQM'] = pd.to_numeric(all_listings_frame['Area in SQM'], errors='coerce')\n",
    "    all_listings_frame[\"Price per SQM\"] = all_listings_frame.apply(lambda row: calculate_price_per_sqm(row['asking_price'], row['total_area_sqft']), axis=1)\n",
    "    all_listings_frame['property_name_clean'] = all_listings_frame.apply(lambda row: create_property_name_clean(row['area_name_prop_ai'], row['development_name_prop_ai'], row['Property Type'], row['Number of Bedrooms']), axis=1)\n",
    "        \n",
    "    # all_listings_frame = all_listings_frame.loc[all_listings_frame['asking_price'] != 0]\n",
    "    # dubai_developments_frame = all_listings_frame[['development_name', 'area_name_en', 'area_name_dropdown']]\n",
    "    # dubai_developments_frame = dubai_developments_frame[dubai_developments_frame['development_name'] != \"\"]\n",
    "    # dubai_developments_frame = dubai_developments_frame.drop_duplicates(subset=['development_name'], keep='first')\n",
    "\n",
    "    # dubai_active_listings_frame = all_listings_frame.loc[(all_listings_frame[\"city_name\"] == \"Dubai\") & (all_listings_frame['for_sale'] == True)]\n",
    "    dubai_active_listings_frame = all_listings_frame.loc[(all_listings_frame[\"city_name\"] == \"Dubai\")]\n",
    "    # dubai_active_listings_frame = dubai_active_listings_frame[dubai_active_listings_frame['area_name_en'] != \"\"]\n",
    "\n",
    "    dubai_active_listings_frame.rename(columns={'photo_urls': 'photo_url_list'}, inplace=True)\n",
    "    dubai_active_listings_frame['photo_url_list'] = dubai_active_listings_frame['photo_url_list'].apply(convert_to_json)\n",
    "        \n",
    "    print(dubai_active_listings_frame.columns)\n",
    "    new_dubai_active_listings_frame = clean_and_transform_dataframe_v2(dubai_active_listings_frame)\n",
    "        \n",
    "    unique_listing_sources = new_dubai_active_listings_frame['listing_source'].unique()\n",
    "    # Printing the unique values\n",
    "    print(\"unique_listing_sources in new_dubai_active_listings_frame:\")\n",
    "    print(unique_listing_sources)\n",
    "    \n",
    "    new_dubai_active_listings_frame['dubailand_listing_validation_url_cleaned'] = new_dubai_active_listings_frame['dubailand_listing_validation_url'].str.extract(r'=(.*)$')\n",
    "    \n",
    "    print('data before creating csv')\n",
    "    print(new_dubai_active_listings_frame.info())  \n",
    "    duplicate_rows = new_dubai_active_listings_frame[new_dubai_active_listings_frame.duplicated(subset=['listing_url'])]\n",
    "    # Count duplicate rows\n",
    "    duplicate_rows_count = duplicate_rows.shape[0]\n",
    "    # Display results\n",
    "    print(f\"Number of Duplicate Rows: {duplicate_rows_count}\") \n",
    "    total_listings = len(new_dubai_active_listings_frame)\n",
    "    unique_listings = new_dubai_active_listings_frame['listing_url'].nunique()\n",
    "    # Calculate the number of duplicate listings\n",
    "    duplicate_listings = total_listings - unique_listings\n",
    "    print(total_listings,unique_listings,duplicate_listings) \n",
    "    \n",
    "    # new\n",
    "    if (marketplace):\n",
    "        csv_buffer = StringIO()\n",
    "        new_dubai_active_listings_frame.to_csv(csv_buffer,index=False)\n",
    "        \n",
    "        s3.Object(DLD_OUTPUT_BUCKET,\n",
    "        f'dld-non-compliant-listings-and-sm-ads/non-compliant-listings/active-listings/{csv_folder_name}/dubai_active_listings_{csv_folder_name}_{marketplace}.csv').put(Body=csv_buffer.getvalue())\n",
    "        \n",
    "    else:      \n",
    "        csv_buffer = StringIO()\n",
    "        new_dubai_active_listings_frame.to_csv(csv_buffer,index=False)\n",
    "            \n",
    "        s3.Object(DLD_OUTPUT_BUCKET,\n",
    "        f'dld-non-compliant-listings-and-sm-ads/non-compliant-listings/active-listings/{csv_folder_name}/dubai_active_listings_{csv_folder_name}.csv').put(Body=csv_buffer.getvalue())   \n",
    "        \n",
    "    # old\n",
    "    if (marketplace):\n",
    "        csv_buffer = StringIO()\n",
    "        new_dubai_active_listings_frame.to_csv(csv_buffer,index=False)\n",
    "        \n",
    "        s3.Object(LISTINGS_OUTPUT_BUCKET_NAME,\n",
    "        f'testing-output/{csv_folder_name}/dubai_active_listings_{csv_folder_name}_{marketplace}.csv').put(Body=csv_buffer.getvalue())\n",
    "        \n",
    "    else:      \n",
    "        csv_buffer = StringIO()\n",
    "        new_dubai_active_listings_frame.to_csv(csv_buffer,index=False)\n",
    "            \n",
    "        s3.Object(LISTINGS_OUTPUT_BUCKET_NAME,\n",
    "        f'testing-output/{csv_folder_name}/dubai_active_listings_{csv_folder_name}.csv').put(Body=csv_buffer.getvalue()) \n",
    "    \n",
    "    \n",
    "    \n",
    "    if (marketplace):\n",
    "        weekly_listings_s3 = pd.read_csv(\n",
    "        f's3://{DLD_OUTPUT_BUCKET}/dld-non-compliant-listings-and-sm-ads/non-compliant-listings/active-listings/{csv_folder_name}/dubai_active_listings_{csv_folder_name}_{marketplace}.csv',\n",
    "        header=0,\n",
    "        storage_options={\"key\": ACCESS_ID, \"secret\": ACCESS_KEY}\n",
    "        ) \n",
    "    else:\n",
    "        weekly_listings_s3 = pd.read_csv(\n",
    "            f's3://{DLD_OUTPUT_BUCKET}/dld-non-compliant-listings-and-sm-ads/non-compliant-listings/active-listings/{csv_folder_name}/dubai_active_listings_{csv_folder_name}.csv',\n",
    "            header=0,\n",
    "            storage_options={\"key\": ACCESS_ID, \"secret\": ACCESS_KEY}\n",
    "        )\n",
    "\n",
    "\n",
    "    print('weekly_listings_s3')\n",
    "    print(weekly_listings_s3.info())\n",
    "    print(weekly_listings_s3.empty)\n",
    "\n",
    "    if not weekly_listings_s3.empty:\n",
    "        logging.info('Adding Active Listing to RDS Started')\n",
    "        clean_table_data('dubai_active_listings',marketplace)        \n",
    "        weekly_listings_s3['scraped_date'] = scraped_date\n",
    "        insert_dataframe_to_postgresql(weekly_listings_s3, 'dubai_active_listings', if_exists=\"append\")        \n",
    "        logging.info('Adding Active Listing to RDS Finished')        \n",
    "    else:\n",
    "        print(\"No data to insert\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf21ced2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_source_column_name_lists_dicts_by_date(date):\n",
    "    source_column_name_lists_dict = {\n",
    "        \"bayut\": None,\n",
    "        \"propertyfinder\": None,\n",
    "        \"zoom\": None,\n",
    "        \"dubizzle\":None\n",
    "    }\n",
    "\n",
    "    if (date in [\"2023-06-28\",\"2023-06-26\",\"2023-06-19\",\"2023-06-12\",\"2023-06-07\",\"2023-06-05\",\"2023-05-29\",\"2023-05-22\"]):\n",
    "        source_column_name_lists_dict[\"zoom\"] = ['url', 'website', 'country', 'city', 'listing_name', 'price', 'price_currency', 'property_type', 'property_sub_type', 'area',\n",
    "                                                'latitude', 'longitude', 'description', 'for_sale', 'for_rent', 'built_area', 'built_area_units', 'bathroom_count', 'room_count',\n",
    "                                                'amenities', 'date_listed', 'email', 'phone', 'reference_number', 'building_name','building_id','is_verified']\n",
    "\n",
    "        source_column_name_lists_dict[\"propertyfinder\"] = ['url', 'website', 'country', 'city', 'listing_name', 'price', 'price_currency', 'property_type',\n",
    "                                                        'property_sub_type', 'address', 'area', 'latitude', 'longitude', 'description', 'for_sale', 'for_rent', 'built_area',\n",
    "                                                        'built_area_units', 'bathroom_count', 'room_count', 'amenities', 'date_listed', 'agent_id', 'agent_call', 'agent_name',\n",
    "                                                        'email', 'broker_id', 'broker_name', 'reference', 'completion_status', 'building_name','dubailand_listing_validation_url','is_verified']\n",
    "\n",
    "        source_column_name_lists_dict[\"bayut\"] = ['url', 'website', 'country', 'city', 'listing_name', 'price', 'price_currency', 'property_type', 'property_sub_type', 'address',\n",
    "                                                'area', 'latitude', 'longitude', 'description', 'for_sale', 'for_rent', 'plot_area', 'plot_area_units', 'bathroom_count',\n",
    "                                                'room_count', 'amenities', 'date_listed', 'bayut_reference_number', 'completion_status','building_name', 'realtor_name', 'realtor_email',\n",
    "                                                'realtor_cell_phone', 'realtor_phone', 'realtor_permit_number', 'agency_name','dubailand_listing_validation_url','trucheck_verified']\n",
    "        \n",
    "    elif (date in [\"2023-07-04\",\"2023-07-11\",\"2023-07-17\",\"2023-07-24\",\"2023-07-31\"]):\n",
    "        source_column_name_lists_dict[\"zoom\"] = ['url', 'website', 'country', 'city', 'listing_name', 'price', 'price_currency', 'property_type', 'property_sub_type', 'area',\n",
    "                                                'latitude', 'longitude', 'description', 'for_sale', 'for_rent', 'built_area', 'built_area_units', 'bathroom_count', 'room_count',\n",
    "                                                'amenities', 'date_listed', 'email', 'phone', 'reference_number', 'agency_id', 'agency_name', 'agent_id', 'agent_name','building_name','building_id','is_verified']\n",
    "\n",
    "\n",
    "        source_column_name_lists_dict[\"propertyfinder\"] = ['url', 'website', 'country', 'city', 'listing_name', 'price', 'price_currency', 'property_type',\n",
    "                                                        'property_sub_type', 'address', 'area', 'latitude', 'longitude', 'description', 'for_sale', 'for_rent', 'built_area',\n",
    "                                                        'built_area_units', 'bathroom_count', 'room_count', 'amenities', 'date_listed', 'agent_id', 'agent_call', 'agent_name',\n",
    "                                                        'email', 'broker_id', 'broker_name', 'reference', 'completion_status', 'building_name','dubailand_listing_validation_url','is_verified']\n",
    "\n",
    "        source_column_name_lists_dict[\"bayut\"] = ['url', 'website', 'country', 'city', 'listing_name', 'price', 'price_currency', 'property_type', 'property_sub_type', 'address',\n",
    "                                                'area', 'latitude', 'longitude', 'description', 'for_sale', 'for_rent', 'plot_area', 'plot_area_units', 'bathroom_count',\n",
    "                                                'room_count', 'amenities', 'date_listed', 'bayut_reference_number', 'completion_status','building_name', 'realtor_name', 'realtor_email',\n",
    "                                                'realtor_cell_phone', 'realtor_phone', 'realtor_permit_number', 'agency_name','dubailand_listing_validation_url','trucheck_verified']\n",
    "    elif (date in [\"2023-08-07\"]):\n",
    "        source_column_name_lists_dict[\"zoom\"] = ['url', 'website', 'country', 'city', 'listing_name', 'price', 'price_currency', 'property_type', 'property_sub_type',\n",
    "                                    'area', 'latitude', 'longitude', 'description', 'for_sale', 'for_rent', 'built_area', 'built_area_units',\n",
    "                                    'bathroom_count', 'room_count', 'amenities', 'date_listed', 'agent_email', 'agent_phone', 'zoomproperty_reference_number',\n",
    "                                    'agency_id', 'agency_name', 'agent_id', \"agent_name\",'building_name','building_id','is_verified']\n",
    "\n",
    "        source_column_name_lists_dict[\"propertyfinder\"] = ['url', 'website', 'country', 'city', 'listing_name', 'price', 'price_currency', 'property_type',\n",
    "                                                'property_sub_type', 'address', 'area', 'latitude', 'longitude', 'description', 'for_sale', 'for_rent',\n",
    "                                                'built_area', 'built_area_units', 'bathroom_count', 'room_count', 'amenities', 'date_listed', 'agent_id',\n",
    "                                                'agent_phone', 'agent_name', 'agent_email', 'propertyfinder_reference_number',\n",
    "                                                'completion_status', 'building_name', 'is_furnished','dubailand_listing_validation_url','is_verified']\n",
    "\n",
    "\n",
    "        source_column_name_lists_dict[\"bayut\"] = ['url', 'website', 'country', 'city', 'listing_name', 'price', 'price_currency', 'property_type', 'property_sub_type',\n",
    "                                    'address', 'area', 'latitude', 'longitude', 'description', 'for_sale', 'for_rent', 'plot_area', 'plot_area_units',\n",
    "                                    'bathroom_count', 'room_count', 'amenities', 'date_listed', 'bayut_reference_number', 'completion_status','building_name', 'agent_name',\n",
    "                                    'agent_email', 'agent_cell_phone', 'agent_phone', 'trakheesi_permit_number', 'agency_name', 'furnishing_status','dubailand_listing_validation_url','trucheck_verified']\n",
    "    else:\n",
    "        #latest\n",
    "        source_column_name_lists_dict[\"zoom\"] = ['url', 'website', 'country', 'city', 'listing_name', 'price', 'price_currency', 'property_type', 'property_sub_type',\n",
    "                                    'area', 'latitude', 'longitude', 'description', 'for_sale', 'for_rent', 'built_area', 'built_area_units',\n",
    "                                    'bathroom_count', 'room_count', 'amenities', 'date_listed', 'agent_email', 'agent_phone', 'zoomproperty_reference_number','agent_whatsapp',\n",
    "                                    'agency_id', 'agency_name', 'agent_id', 'agent_name','building_name','trakheesi_permit_number','agency_orn','agent_orn','building_id','is_verified']\n",
    "\n",
    "        source_column_name_lists_dict[\"propertyfinder\"] = ['url', 'website', 'country', 'city', 'listing_name', 'price', 'price_currency', 'property_type',\n",
    "                                                'property_sub_type', 'address', 'area', 'latitude', 'longitude', 'description', 'for_sale', 'for_rent',\n",
    "                                                'built_area', 'built_area_units', 'bathroom_count', 'room_count', 'amenities', 'date_listed', 'agent_id',\n",
    "                                                'agent_phone', 'agent_name', 'agent_email', 'agency_id', 'agency_name', 'propertyfinder_reference_number','agent_whatsapp',\n",
    "                                                'completion_status', 'building_name', 'furnishing_status','agent_brn_number', 'trakheesi_permit_number','agency_orn_number','dubailand_listing_validation_url','is_verified']\n",
    "\n",
    "\n",
    "        source_column_name_lists_dict[\"bayut\"] = ['url','city', 'listing_name', 'price', 'price_currency', 'property_type', 'property_sub_type',\n",
    "                                    'address', 'area', 'latitude', 'longitude', 'description', 'for_sale', 'for_rent', 'plot_area', 'plot_area_units',\n",
    "                                    'bathroom_count', 'room_count', 'amenities', 'date_listed', 'bayut_reference_number', 'completion_status','building_name', 'agent_name',\n",
    "                                    'agent_email', 'agent_cell_phone', 'agent_phone', 'trakheesi_permit_number', 'agency_name', 'furnishing_status','community_name', 'agent_whatsapp',\n",
    "                                    'agent_brn_number','dubailand_listing_validation_url','rera_trakheesi_listing_permit',\n",
    "                                    \"building_built_date\", \"building_floor_count\", \"building_builtup_area_sqm\", \"developer_project_name\", \"listing_floor_number\", \"trakheesi_start\", \"trakheesi_end\", \"is_qr_code_link_available\", \"regulatory_status\", \"is_permit_delisted\", \"orn_license\", \"ded_license\", \"rera_license\", \"service_charge_sqft\",'trucheck_verified']\n",
    "\n",
    "        source_column_name_lists_dict[\"dubizzle\"] =  [\n",
    "                                        'url', 'country', 'city', 'region', 'address', 'property_category', \n",
    "                                        'agency_id', 'agency_name', 'agent_name', 'agent_email',\n",
    "                                        'agent_id', 'agent_phone', 'agent_brn', 'listing_price', 'listing_price_currency',\n",
    "                                        'listing_size', 'listing_bathrooms', 'listing_bedrooms', 'amenities', 'lat', 'lon',\n",
    "                                        'listing_description', 'listing_name', 'trakheesi_permit_number',\n",
    "                                        'property_sub_category', 'property_furnished', 'property_completion_status', 'for_sale',\n",
    "                                        'for_rent', 'property_updated_at', 'property_listing_id', 'dubailand_listing_validation_url',\n",
    "                                        'photos_main_urls', 'building_name','rera_registration_number'\n",
    "                                    ]\n",
    "\n",
    "    return source_column_name_lists_dict\n",
    "\n",
    "# data processing function section \n",
    "def create_photo_url_objs(urls):\n",
    "    url_objs =[]\n",
    "    if type(urls)==float:\n",
    "        return url_objs\n",
    "    for i in range(len(urls)):\n",
    "        if i<5:\n",
    "            url_objs.append({\n",
    "                \"url\": urls[i],\n",
    "                \"propai_selected\": True\n",
    "            })\n",
    "        else:\n",
    "            url_objs.append({\n",
    "                \"url\": urls[i],\n",
    "                \"propai_selected\": False\n",
    "            })\n",
    "    return url_objs\n",
    "\n",
    "def clean_address(address):\n",
    "    if isinstance(address, str):\n",
    "        return address.upper().strip().replace(r'\\s{2,}', ' ').replace(',', '')\n",
    "    else:\n",
    "        # Return a default value or handle the non-string input appropriately\n",
    "        return ''\n",
    " \n",
    "def merge_columns(row):\n",
    "    if row['master_project_en']!=\"\" and row['project_name_en']!=\"\":\n",
    "        return f\"{row['master_project_en']}, {row['project_name_en']}\"\n",
    "    elif row['master_project_en']!=\"\":\n",
    "        return row['master_project_en']\n",
    "    else:\n",
    "        return row['project_name_en']\n",
    "\n",
    "def calculate_price_per_sqm(asking_price, total_area_sqft):\n",
    "  if total_area_sqft == 0:\n",
    "    return np.nan\n",
    "  else:\n",
    "    return asking_price / total_area_sqft\n",
    "\n",
    "def clean_and_transform_dataframe_v2(df):\n",
    "    # Text Columns: Remove leading/trailing spaces and replace NaN with ''\n",
    "    # Ensure that columns are of string type before applying string methods\n",
    "    text_columns = ['listing_url', 'listing_source', 'country_name', 'city_name', 'property_name', \n",
    "                    'asking_price_currency', 'property_category', 'property_type',\n",
    "                     'property_address', \n",
    "                    'city_region', 'listing_id', 'completion_status', 'list_agent_full_name', \n",
    "                    'list_agent_email', 'list_office_name',\n",
    "                    'agent_whatsapp','description','trakheesi_permit_number', 'trakheesi_start', 'trakheesi_end','date_listed', 'date_scraped',\n",
    "                    'property_name_clean','master_project_en','address',\n",
    "                    'Property Type','developer_project_name','regulatory_status','orn_license','ded_license','rera_license','dubailand_listing_validation_url','building_built_date',\n",
    "                    'project_name_prop_ai','master_project_prop_ai','area_name_prop_ai','development_name_prop_ai',\n",
    "                    \"dld_agent_full_name\", \"dld_broker_office_name\", \"dld_agent_email\", \"dld_agent_mobile\", \"dld_agent_landline\"]\n",
    "    for col in text_columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = ''  # Add the missing column with empty strings\n",
    "        df[col] = df[col].astype(str).str.strip().fillna('')\n",
    "\n",
    "    # Numeric Columns: Convert to numeric and replace NaN with 0\n",
    "    numeric_columns = ['asking_price', 'map_coordinates_latitude', 'map_coordinates_longitude', \n",
    "                       'bathrooms_total', 'rooms_total', 'list_agent_mobile_phone', 'total_area_sqm', \n",
    "                       'total_area_sqft','building_floor_count','building_builtup_area_sqm','listing_floor_number','service_charge_sqft','list_agent_direct_phone',\n",
    "                       \"Number of Bedrooms\",\"Area in SQM\",\"Price per SQM\"\n",
    "                       ]\n",
    "    # Ensure all numeric columns are present\n",
    "    for col in numeric_columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0  # Add the missing column with 0s\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
    "\n",
    "    # Boolean Columns: Ensure boolean format\n",
    "    boolean_columns = ['for_sale', 'for_rent','is_verified','furnished_yn','is_qr_code_link_available','is_permit_delisted']\n",
    "    for col in boolean_columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = False  # Add the missing column with False\n",
    "        df[col] = df[col].astype(bool)\n",
    "\n",
    "    datetime_columns = []\n",
    "\n",
    "    for col in datetime_columns:\n",
    "        # Replace empty strings, None, and '0' values with '1/1/1970'\n",
    "        df[col] = df[col].replace(['', '0', None], '01/01/1970')\n",
    "        \n",
    "        # Convert string to datetime object\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "        \n",
    "        # Format datetime object as string in 'YYYY-MM-DD' format\n",
    "        df[col] = df[col].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "    df=df.fillna(0)\n",
    "    return df\n",
    "\n",
    "def fetch_data_ordered_by_date(connection, table_name):\n",
    "    cursor = connection.cursor()\n",
    "    fetch_query = f\"SELECT * FROM {table_name} ORDER BY date_scraped DESC;\"\n",
    "    try:\n",
    "        cursor.execute(fetch_query)\n",
    "        rows = cursor.fetchall()\n",
    "        return rows\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        cursor.close()\n",
    "\n",
    "def combine_photo_urls(row):\n",
    "    url = row['photo_url']\n",
    "    urls = row['photo_urls']\n",
    "\n",
    "    if url in [None, '[]'] and urls in [None, '[]']:\n",
    "        return None\n",
    "    elif url in [None, '[]']:\n",
    "        return urls\n",
    "    elif urls in [None, '[]']:\n",
    "        return url\n",
    "    else:\n",
    "        return f\"{url}, {urls}\"  # Concatenating URLs\n",
    "    \n",
    "def convert_to_json(data):\n",
    "    if isinstance(data, (dict, list)):\n",
    "        return json.dumps(data)\n",
    "    return data\n",
    "\n",
    "def map_values(value):\n",
    "    if value == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False   \n",
    "\n",
    "\n",
    "# database functions section \n",
    "def get_postgres_connection():\n",
    "    return psycopg2.connect(\n",
    "        host=DB_HOST,\n",
    "        port=DB_PORT,\n",
    "        dbname=DB_NAME,\n",
    "        user=DB_USERNAME,\n",
    "        password=DB_PASSWORD\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba4f12d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_table_if_not_exists(connection, table_name):\n",
    "    cursor = connection.cursor()\n",
    "    create_table_query = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "    listing_url TEXT PRIMARY KEY,\n",
    "    date_scraped VARCHAR,   \n",
    "    listing_source VARCHAR,\n",
    "    country_name VARCHAR,\n",
    "    city_name VARCHAR,\n",
    "    property_name TEXT,\n",
    "    asking_price NUMERIC,\n",
    "    asking_price_currency VARCHAR,\n",
    "    property_category VARCHAR,\n",
    "    property_type VARCHAR,\n",
    "    property_address TEXT,\n",
    "    photo_url_list TEXT,\n",
    "    description TEXT,\n",
    "    city_region VARCHAR,\n",
    "    map_coordinates_latitude NUMERIC,\n",
    "    map_coordinates_longitude NUMERIC,\n",
    "    for_sale BOOLEAN,\n",
    "    for_rent BOOLEAN,\n",
    "    bathrooms_total NUMERIC,\n",
    "    rooms_total NUMERIC,\n",
    "    amenities_text TEXT,\n",
    "    date_listed VARCHAR,\n",
    "    listing_id VARCHAR,\n",
    "    completion_status VARCHAR,\n",
    "    list_agent_full_name VARCHAR,\n",
    "    list_agent_email VARCHAR,\n",
    "    agent_whatsapp VARCHAR,\n",
    "    list_agent_mobile_phone NUMERIC,\n",
    "    list_agent_direct_phone NUMERIC,\n",
    "    list_office_name VARCHAR,\n",
    "    furnished_info VARCHAR,\n",
    "    community_name VARCHAR,\n",
    "    agent_brn_number VARCHAR,\n",
    "    trakheesi_permit_number VARCHAR,\n",
    "    is_verified BOOLEAN,\n",
    "    total_area_sqm NUMERIC,\n",
    "    total_area_sqft NUMERIC,\n",
    "    furnished_yn BOOLEAN,\n",
    "    list_agent_mls_id VARCHAR,\n",
    "    list_office_mls_id VARCHAR,\n",
    "    agency_name VARCHAR,\n",
    "    building_name VARCHAR,\n",
    "    property_address_clean VARCHAR,\n",
    "    agency_orn VARCHAR,\n",
    "    address TEXT,\n",
    "    project_name_en VARCHAR,\n",
    "    master_project_en TEXT,\n",
    "    area_name_en VARCHAR,\n",
    "    development_name VARCHAR,\n",
    "    \"Property Type\" VARCHAR,\n",
    "    \"Number of Bedrooms\" NUMERIC,\n",
    "    \"Development Status\" VARCHAR,\n",
    "    \"Area in SQM\" NUMERIC,\n",
    "    \"Price per SQM\" NUMERIC,\n",
    "    property_name_clean TEXT,\n",
    "    building_built_date VARCHAR,\n",
    "    building_floor_count NUMERIC,\n",
    "    building_builtup_area_sqm NUMERIC,\n",
    "    developer_project_name VARCHAR,\n",
    "    listing_floor_number NUMERIC,\n",
    "    trakheesi_start VARCHAR,\n",
    "    trakheesi_end VARCHAR,\n",
    "    is_qr_code_link_available BOOLEAN,\n",
    "    regulatory_status VARCHAR,\n",
    "    is_permit_delisted BOOLEAN,\n",
    "    orn_license VARCHAR,\n",
    "    ded_license VARCHAR,\n",
    "    rera_license VARCHAR,\n",
    "    service_charge_sqft NUMERIC,\n",
    "    dubailand_listing_validation_url VARCHAR,\n",
    "    project_name_prop_ai VARCHAR,\n",
    "    master_project_prop_ai VARCHAR,\n",
    "    area_name_prop_ai VARCHAR,\n",
    "    development_name_prop_ai VARCHAR,\n",
    "    dld_agent_full_name VARCHAR(255),\n",
    "    dld_broker_office_name VARCHAR(255),\n",
    "    dld_agent_email VARCHAR(255),\n",
    "    dld_agent_mobile VARCHAR(20),\n",
    "    dld_agent_landline VARCHAR(20)\n",
    "    ); \"\"\"\n",
    "    try:\n",
    "        cursor.execute(create_table_query)\n",
    "        connection.commit()\n",
    "    except Exception as e:\n",
    "        connection.rollback()\n",
    "        raise e\n",
    "    finally:\n",
    "        cursor.close()\n",
    "\n",
    "def insert_into_postgresql_unique_listing_url(data, table_name):\n",
    "    if not data or not isinstance(data, list):\n",
    "        raise ValueError(\"Data is empty or not in the expected format (list)\")\n",
    "\n",
    "    conn = get_postgres_connection()\n",
    "    create_table_if_not_exists(conn, table_name)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "\n",
    "    columns = data[0].keys()\n",
    "    quoted_columns = [quote_col(col) for col in columns]\n",
    "    placeholders = ', '.join(['%s'] * len(quoted_columns))\n",
    "\n",
    "    insert_query = f\"INSERT INTO {table_name} ({','.join(quoted_columns)}) VALUES ({placeholders}) \"\n",
    "\n",
    "    # Modify the ON CONFLICT action\n",
    "    conflict_action = \"ON CONFLICT (listing_url) DO UPDATE SET \"\n",
    "    update_columns = ', '.join([f\"{quote_col(col)} = EXCLUDED.{quote_col(col)}\" \n",
    "                                for col in columns \n",
    "                                if col != 'listing_url'])\n",
    "    query = insert_query + conflict_action + update_columns\n",
    "\n",
    "    values = [tuple(item[col] for col in columns) for item in data]\n",
    "\n",
    "    try:\n",
    "        execute_batch(cursor, query, values)\n",
    "        conn.commit()\n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        raise e\n",
    "    finally:\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "def insert_dataframe_to_postgresql(df, table_name, if_exists=\"append\"):\n",
    "    try:\n",
    "        engine = create_engine(DB_URI)\n",
    "        df.to_sql(table_name, engine, if_exists=if_exists, index=False)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error while inserting dataframe to PostgreSQL: {e}\")\n",
    "\n",
    "def quote_col(col):    \n",
    "    # Function to quote column names if they contain spaces or special characters\n",
    "    if \" \" in col or '\"' in col:\n",
    "        return f'\"{col}\"'\n",
    "    return col\n",
    "\n",
    "def clean_table_data(table_name, marketplace):\n",
    "    try:\n",
    "        conn = get_postgres_connection()\n",
    "        cur = conn.cursor()\n",
    "        if(marketplace):\n",
    "            cur.execute(\n",
    "                f'DELETE FROM {table_name} WHERE \"listing_source\" = %s AND \"scraped_date\" = %s;',\n",
    "                (marketplace, scraped_date)\n",
    "            )\n",
    "            conn.commit()  # Commit the changes to make sure records are deleted\n",
    "            print(f\"Records matching {scraped_date} & {marketplace}  have been deleted from {table_name}.\")\n",
    "        else:\n",
    "            cur.execute(\n",
    "                f'DELETE FROM {table_name} WHERE \"scraped_date\" = %s;', (scraped_date,)\n",
    "            )\n",
    "            conn.commit()  # Commit the changes to make sure records are deleted\n",
    "            print(f\"Records matching {scraped_date}  have been deleted from {table_name}.\") \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error while clearing data from {table_name}: {e}\")\n",
    "    finally:\n",
    "        if cur:\n",
    "            cur.close()\n",
    "        if conn:\n",
    "            conn.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
